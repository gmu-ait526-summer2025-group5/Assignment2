{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13fd34b4-1de1-4554-94c1-fe6a94ba3769",
   "metadata": {},
   "source": [
    "Group Programming Assignment Two-QA System <br>\n",
    "Kori Fogle, Michaela Herrick, Jackson Holland, Ishaan Indoori <br>\n",
    "AIT 526 <br>\n",
    "6/18/2025 <br>\n",
    "\n",
    "<b> Problem to be Solved </b> <br>\n",
    "The goal of this program is to create a question answering system executable from the command line. These questions must begin with \"who,\" \"what,\" \"when,\" or \"where\" and must return a portion of the question back to the user along with the answer. Unclear questions or questions to which answers cannot be found must be addressed. A log file must be created within the program, and users must be able to exit the chat.\n",
    " <br>\n",
    "<b> Algorithm and Flow</b><br>\n",
    "Our program utilizes a class that contains several functions to accomplish the above goal. First, we loaded all relevant packages. Particularly, this program will use a Wikipedia API to return answers back to a user. We then initialize a log file, as well as create a way for the user to exit. These questions must begin with \"who,\" \"what,\" \"when,\" or \"where.\" The program uses regular expressions and if statements to parse user input, then return answers that rephrase part of the user's original question along with the answer. The user’s input is then categorized into one five types of questions- a who question, a what question, a where question, a when question, or an unclear/ unanswerable question. These questions, except for unclear/ unanswerable questions, are then queried using the Wikipedia API. An answer is then returned to the user. The program also alerts users when it is given a question it cannot answer with a phrase such as \"I'm sorry, I don't quite know the answer.\" Further, users can exit the program using the word \"exit.\" This program also creates a log file that can be referenced after program ends to review input and output. Finally, error handling is included to address specific errors, such as pages not loading, or too many possible answers being returned.\n",
    "<br>\n",
    "<b> Example of Input and Output</b><br>\n",
    "\n",
    "<b> Usage Instructions</b><br>\n",
    "<oi>\n",
    "<li>Execute the program</li>\n",
    "<li>You'll be asked to input a name for the log file. Name this file as you would any other file. It will be accessible in the same working directory as this program.</li>\n",
    "<li>Instructions will prompt you to start all questions with who, what, when, or where.</li>\n",
    "<li>Ask a question and wait for the response</li>\n",
    "<li>Stop asking questions by typing the word \"exit.\"</li>\n",
    "</ol><br>\n",
    "\n",
    "<b> References</b><br>\n",
    "Anon. 2024. “Python Regex Cheat Sheet.” GeeksforGeeks. Retrieved May 31, 2025 (https://www.geeksforgeeks.org/python-regex-cheat-sheet/).<br>\n",
    "Dib, Firas. n.d. “Regex101 - Online Regex Editor and Debugger.” @Regex101.(https://regex101.com/).<br>\n",
    "Gadiraju, Sai Surya. n.d. “Program Assignment 2 Demo Video.”<br>\n",
    "Jurafsky, Daniel, and James H. Martin. 2025. Speech and Language Processing (3rd Ed. Draft).<br>\n",
    "Liao, Duoduo. n.d. \"Tips and Hints- QA System Programming Assignment-2.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "199f8e48-5c21-4271-8274-b9f091ac2125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load relevant packages and en_core_web_sm\n",
    "import sys\n",
    "import wikipedia\n",
    "import wikipedia.exceptions as wiki_exceptions\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "import spacy\n",
    "from difflib import SequenceMatcher\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17431b0c-a09d-48f6-b2b8-29dab0126176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** This is a QA system. I will try to answer questions that start with Who, What, When, and Where. Type Exit to quit. ***\n",
      "Trying to search Wikipedia for the question: electron\n"
     ]
    }
   ],
   "source": [
    "#Much of the code below is derived from (Liao, n.d.) and (Gadiraju, n.d.).\n",
    "#Create a class to hold functions\n",
    "class QA_System:\n",
    "    def __init__(self, logfile):\n",
    "        self.logfile = logfile\n",
    "\n",
    "    def run(self):\n",
    "        print(\"*** This is a QA system. I will try to answer questions that start with Who, What, When, and Where. Type Exit to quit. ***\")\n",
    "        while True:\n",
    "            try:\n",
    "                question = input(\"*?>\").strip()\n",
    "                if question.lower() in [\"exit\", \"quit\", \"bye\", \"goodbye\"]:\n",
    "                    print(\"Thank you, goodbye\")\n",
    "                    break\n",
    "                self.answer_question(question)\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "\n",
    "    def answer_question(self, question):\n",
    "        doc = nlp(question)\n",
    "        question_type = self.identify_question_type(question)\n",
    "        if question_type is None:\n",
    "            print(\"I'm sorry I don't quite know the answer to this question.\")\n",
    "            self.log_question(question, \"n/a\")\n",
    "            return \n",
    "        refined_query = self.extract_context(question)\n",
    "        if not refined_query:\n",
    "            refined_query = self.extract_dynamic_entity(doc, question_type)\n",
    "        if refined_query: \n",
    "            print(f\"Trying to search Wikipedia for the question: {refined_query}\")\n",
    "            self.search_wikipedia(refined_query, question_type, question)\n",
    "        else:\n",
    "            print(\"I'm sorry, but I was unable to find an answer. Make sure you've phrased your question correctly.\")\n",
    "\n",
    "    def identify_question_type(self, question):\n",
    "        question_lower = question.lower()\n",
    "        if question_lower.startswith(\"who\"):\n",
    "            return \"Who\"\n",
    "        elif question_lower.startswith(\"what\"):\n",
    "            return \"What\"\n",
    "        elif question_lower.startswith(\"when\"):\n",
    "            return \"When\"\n",
    "        elif question_lower.startswith(\"where\"):\n",
    "            return \"Where\"\n",
    "        return None\n",
    "\n",
    "    def extract_context(self, question):\n",
    "        patternWhoIs = [r'Who (Is|Was|are|) (.+)']\n",
    "        patternWhoLong = [r'Who (?:owns|founded|leads|led|made|makes|created|invented|discovered|wrote) (.+)']\n",
    "        patternWhat = [r'what (Is|Was) ( .* ) Age', r'What (Is|Was) (.+)', r'What (.+)']\n",
    "        patternWhen = [\n",
    "            r'When (?:is|was) (.+) born',\n",
    "            r'When (?:is|was) (.+) birthday',\n",
    "            r'When did (.+)',\n",
    "            r'When (Is|Was) ( .. ) Born',\n",
    "            r'When (Is|Was) (.+) Birthday',\n",
    "            r'When (.+) Born',\n",
    "            r'When (.+) Birthday',\n",
    "            r'When did (.+)'\n",
    "        ]\n",
    "        patternWhere = [r'Where (.+)', r'Where (?:is|was|are|did) (.+)']\n",
    "        patterns = patternWhoIs + patternWhoLong + patternWhat + patternWhen + patternWhere\n",
    "\n",
    "        for pattern in patterns:\n",
    "            match = re.match(pattern, question, re.IGNORECASE)\n",
    "            if match:\n",
    "                return match.group(len(match.groups())).strip()\n",
    "        return None\n",
    "\n",
    "    def extract_dynamic_entity(self, doc, question_type):\n",
    "        entities = [ent.text for ent in doc.ents if ent.label_ in {\"PERSON\", \"ORG\", \"GPE\", \"DATE\"}]\n",
    "        if entities:\n",
    "            return \" \".join(entities)\n",
    "        return re.sub(r'[^a-zA-Z0-9\\s]', '', doc.text).strip().lower()\n",
    "\n",
    "    def fuzzy_match(self, subject, results):\n",
    "        def similarity(a, b):\n",
    "            return SequenceMatcher(None, a.lower(), b.lower()).ratio()\n",
    "        ranked = sorted(results, key=lambda title: similarity(subject, title), reverse=True)\n",
    "        return ranked[0] if ranked else None\n",
    "\n",
    "    def search_wikipedia(self, query, question_type, question):\n",
    "        try:\n",
    "            search_results = wikipedia.search(query)\n",
    "            if not search_results:\n",
    "                print(\"I am sorry I cannot seem to find the answer.\")\n",
    "                self.log_question(question, \"n/a\")\n",
    "                return\n",
    "            chosen_title = self.fuzzy_match(query, search_results) or search_results[0]\n",
    "            try:\n",
    "                page = wikipedia.page(chosen_title, auto_suggest=False)\n",
    "            except wiki_exceptions.DisambiguationError as e:\n",
    "                print(\"This question is rather ambiguous, but here are some possible answers:\")\n",
    "                for option in e.options[:5]:\n",
    "                    print(f\"- {option}\")\n",
    "                self.log_question(question, \"Ambiguous question.\")\n",
    "                return\n",
    "\n",
    "            summary_sentences = sent_tokenize(page.summary)\n",
    "            content_sentences = sent_tokenize(page.content)\n",
    "            combined_sentences = summary_sentences + content_sentences[:25]\n",
    "\n",
    "            meaningful_summary = self.summarize_text(combined_sentences, question_type, query, question)\n",
    "            if meaningful_summary:\n",
    "                print(f\"=> {meaningful_summary}\")\n",
    "                self.log_question(question, meaningful_summary)\n",
    "            else:\n",
    "                print(\"I am sorry I cannot seem to find the answer.\")\n",
    "                self.log_question(question, \"N/A\")\n",
    "\n",
    "        except wiki_exceptions.PageError:\n",
    "            print(\"Unfortunately I could not find a page on that topic.\")\n",
    "            self.log_question(question, \"no result\")\n",
    "\n",
    "        except wiki_exceptions.HTTPTimeoutError:\n",
    "            print(\"There's a network error, check your internet connection and try again.\")\n",
    "            self.log_question(question, \"timeout\")\n",
    "\n",
    "    def summarize_text(self, sentences, question_type, query, full_question):\n",
    "        doc_query = nlp(query)\n",
    "        clean_name = self.clean_display_name(query)\n",
    "\n",
    "        if question_type == \"Who\":\n",
    "            for sentence in sentences:\n",
    "                if query.lower() in sentence.lower() and (\"is\" in sentence or \"was\" in sentence):\n",
    "                    return sentence\n",
    "            return sentences[0] if sentences else None\n",
    "\n",
    "        elif question_type == \"What\":\n",
    "            return sentences[0] if sentences else None\n",
    "\n",
    "        elif question_type == \"When\":\n",
    "            doc = nlp(query)\n",
    "            is_person = any(ent.label_ == \"PERSON\" for ent in doc.ents)\n",
    "            is_death = bool(re.search(r'\\b(die|death|passed away|dead)\\b', query, re.IGNORECASE))\n",
    "            full_date_pattern = r'([A-Z][a-z]+ \\d{1,2}, \\d{4})'\n",
    "\n",
    "            for sentence in sentences:\n",
    "                if is_death:\n",
    "                    match = re.search(r'died on ' + full_date_pattern, sentence)\n",
    "                    if match:\n",
    "                        return f\"{clean_name} died on {match.group(1)}.\"\n",
    "                    match_alt = re.search(r'on ' + full_date_pattern + r' and died', sentence)\n",
    "                    if match_alt:\n",
    "                        return f\"{clean_name} died on {match_alt.group(1)}.\"\n",
    "\n",
    "                if is_person:\n",
    "                    match = re.search(r'born on ' + full_date_pattern, sentence)\n",
    "                    if match:\n",
    "                        return f\"{clean_name} was born on {match.group(1)}.\"\n",
    "                    match_alt = re.search(r'on ' + full_date_pattern + r' and born', sentence)\n",
    "                    if match_alt:\n",
    "                        return f\"{clean_name} was born on {match_alt.group(1)}.\"\n",
    "\n",
    "                if not is_person:\n",
    "                    match = re.search(\n",
    "                        r'(?:started|began|occurred|established|founded|created|formed|launched)(?: in| on)? ' + full_date_pattern,\n",
    "                        sentence, re.IGNORECASE)\n",
    "                    if match:\n",
    "                        return f\"{clean_name} was established on {match.group(1)}.\"\n",
    "\n",
    "            for sent in sentences:\n",
    "                sent_doc = nlp(sent)\n",
    "                for ent in sent_doc.ents:\n",
    "                    if ent.label_ == \"DATE\" and re.search(r'\\d{4}', ent.text):\n",
    "                        if is_death:\n",
    "                            return f\"While the exact date is unclear, it appears {clean_name} died in {ent.text}.\"\n",
    "                        elif is_person:\n",
    "                            return f\"While the exact date is unclear, it appears {clean_name} was born in {ent.text}.\"\n",
    "                        else:\n",
    "                            return f\"While the exact date is unclear, it appears {clean_name} was established in {ent.text}.\"\n",
    "\n",
    "            return \"Date or time information not found.\"\n",
    "\n",
    "        elif question_type == \"Where\":\n",
    "            for sentence in sentences:\n",
    "                if \"GPE\" in [ent.label_ for ent in nlp(sentence).ents]:\n",
    "                    return sentence\n",
    "            return \"Location information not found.\"\n",
    "\n",
    "    def log_question(self, question, answer):\n",
    "        with open(self.logfile, 'a', encoding='utf-8') as log:\n",
    "            log.write(f\"Question: {question}\\n\")\n",
    "            log.write(f\"Answer: {answer}\\n\\n\")\n",
    "\n",
    "    def clean_display_name(self, query):\n",
    "        query = re.sub(\n",
    "            r'\\b(when|was|did|is|born|died|created|founded|started|start|begin|began|occurred|occur|took place|happen|happened)\\b',\n",
    "            '',\n",
    "            query,\n",
    "            flags=re.IGNORECASE\n",
    "        )\n",
    "        query = re.sub(r'\\s+', ' ', query).strip(\"? \").strip()\n",
    "        return query.title()\n",
    "\n",
    "\n",
    "def main():\n",
    "    log_filename = input(\"Enter the name of the log file: \").strip()\n",
    "    try:\n",
    "        qa_system = QA_System(log_filename)\n",
    "        qa_system.run()\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "    finally:\n",
    "        print(\"Log is saved.\")\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b526e2d6-ee6d-415c-b220-0134dec5917e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
